dataset: senticap # senticap,flickrstyle10k
style_type: roberta  #'style_embed' or 'emoji' or 'erc' or 'roberta'
data_split: test #val, test #todo
model: stylized_zero_cap_experiments # stylized_zero_cap_experiments, capdec

metrics:
#  senticap: [CLIPScore, style_classification_roberta, fluency]
  senticap: [CLAPScore, CLIPScore, fluency]
  flickrstyle10k: [CLIPScore, style_classification_emoji, fluency]
style: ['negative']
styles: ['negative']

###audio
use_audio_model: True
audio_model_sampling_rate: 48000
#background audio
#laughter
audio_temperature: 0.16774988500573 #0.01
audio_path: ~/data/for_audio/child_laughing.wav
audio_sampling_rate: 44100
suffix_file_name: "laughter" #""

#crying2_test
#audio_temperature: 0.595 #0.01
#audio_path: ~/data/for_audio/crying.wav
#audio_sampling_rate: 48000
#suffix_file_name: "crying" #""

#ambulance
#audio_temperature: 0.07437
#audio_path: ~/data/for_audio/ambulance.wav
#audio_sampling_rate: 24000
#suffix_file_name: "ambulance" #""

update_ViT: False

desired_labels:
  senticap: [positive, negative] #[factual, positive, negative]
  flickrstyle10k: [humor, romantic] #[factual, humor, romantic]
res_path2eval:
  senticap:
#    audio: /Users/danielabendavid/experiments/zero_style_cap/senticap/roberta/StylizedZeroCap_audio_laughter_kids1_sw_f_zerocap/28_09_2023/total_results_text_style_28_09_2023.csv
# ambulance
#    audio: /Users/danielabendavid/experiments/zero_style_cap/senticap/roberta/StylizedZeroCap_audio_ambulance3_test/30_01_2024/tmp/tmp/total_results_text_style_tmp.csv
# crying
#    audio: /Users/danielabendavid/experiments/zero_style_cap/senticap/roberta/StylizedZeroCap_audio_crying2_test/26_01_2024/tmp/results_13_01_44__26_01_2024.csv
# laughter
#    audio: /Users/danielabendavid/experiments/zero_style_cap/senticap/roberta/StylizedZeroCap_audio_laughter_kids1_final/12_01_2024/tmp/results_02_34_13__12_01_2024.csv
    #source_zerocap
    audio: /Users/danielabendavid/experiments/zero_style_cap/senticap/roberta/source_zero_stylecap_test/03_02_2024/tmp/total_results_text_style_tmp.csv

  flickrstyle10k:
    mul: /Users/danielabendavid/experiments/zero_style_cap/flickrstyle10k/emoji/StylizedZeroCap_mul_clip_style_v2_romantic_test/total_results_text_style_StylizedZeroCap_mul_clip_style_v2_romantic_test.csv

# finetuned roBERTa
finetuned_roberta_model_path: ~/checkpoints/finetuned_roberta/pytorch_model.bin
finetuned_roberta_config: ~/checkpoints/finetuned_roberta/config.json

labels_dict_idxs_roberta:
  senticap:
    positive: 2
    negative: 0
  flickrstyle10k:
    humor: 0
    romantic: 1

max_num_imgs2test:
  senticap: -1
  flickrstyle10k: 1000


tgt_eval_results_file_name: avg_evaluation.csv
tgt_eval_results_file_name_for_all_frames: evaluation_all_frames.csv

tgt_eval_results_path: ~/experiments/stylized_zero_cap_experiments/27_2_23/avg_evaluation.csv
tgt_eval_results_path_for_all_frames: ~/experiments/stylized_zero_cap_experiments/27_2_23/evaluation_all_frames.csv
dir_path_for_eval_only_fluency: ~/experiments/stylized_zero_cap_experiments/27_2_23/fluency_statistics

factual_captions_path:
  senticap: /Users/danielabendavid/data/source/coco/factual_captions.pkl

annotations_path:
  senticap: /Users/danielabendavid/data/senticap/annotations
  flickrstyle10k: /Users/danielabendavid/data/flickrstyle10k/annotations

imgs_path:
  senticap: /Users/danielabendavid/data/senticap/images
  flickrstyle10k: /Users/danielabendavid/data/flickrstyle10k/images
test_imgs:
  senticap: /home/nlp/tzufar/data/senticap/images/test
  flickrstyle10k: /home/nlp/tzufar/data/flickrstyle10k/images/test

labels_dict_idxs:
  senticap:
    positive: 0
    negative: 1
  flickrstyle10k:
    humor: 0
    romantic: 1

#emoji
use_single_emoji_style: False
idx_emoji_style_dict:
  senticap:
#    positive: 53
#    negative: 34
    positive: [0,4,6,7,8,13,15,16,17,18,23,24,36,40,53,60] # 53
    negative: [1,2,3,5,12,22,27,29,32,34,35,37,39,42,43,44,45,46,52,55,56,58] # 34
  flickrstyle10k:
    humor: [0,53] #0
    romantic: [4, 8, 18, 23, 24] #23

emoji_vocab_path: ~/projects/torchMoji/model/vocabulary.json
emoji_pretrained_path: ~/projects/torchMoji/model/pytorch_model.bin
maxlen_emoji_sentence: 30
num_classes: 64

#using my trained text classification model
txt_cls_model_paths:
  senticap: ~/checkpoints/best_models/senticap/best_senticap_text_style_classification_model.pth
  flickrstyle10k: ~/checkpoints/best_models/flickrstyle10k/best_flickrstyle10k_text_style_classification_model.pth
hidden_state_to_take_txt_cls:
  senticap: -1
  flickrstyle10k: -1

#using my trained embedding model
txt_embed_model_paths:
  senticap: ~/checkpoints/best_models/senticap/best_text_style_embedding_model_senticap.pth
  flickrstyle10k: ~/checkpoints/best_models/flickrstyle10k/best_text_style_embedding_model_flickrstyle10k.pth

hidden_state_to_take_txt_style_embedding:
  senticap: -2

model_based_on: 'bert'
