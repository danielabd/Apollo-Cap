###### stylized ZeroCap: create captions - for run.py
debug: False
debug_mac: False
wandb_mode: online #'disabled, offline, online'
data_type: val
#specific_imgs_to_test: [225571, 471814, 72873, 357322, 106314, 368459, 575135, 423830, 51258, 265596, 551518, 448703]
#specific_img_idxs_to_test: [60, 61, 62, 63, 64, 65, 66, 67, 128, 129, 130, 131, 132, 133, 134, 135]

model_based_on: 'bert' # 'clip' /  'bert'

max_num_of_imgs: 5 #-1
specific_idxs_to_skip: [2,3]

target_seq_length: 15
desired_labels: [positive, negative] #[factual, positive, ngeative]
##todo
#max_num_of_imgs: 1
#target_seq_length: 2
#desired_labels: [positive] #[factual, positive, ngeative]


use_style_model: True
use_text_style_example: False
run_type: caption #caption, arithmetics, img_prompt_manipulation
global_dir_name_for_save_models: senticap_ZeroStyleCap

hidden_state_to_take_txt_cls: -1
scale_noise_txt_cls: 0

hidden_state_to_take_txt_style_embedding: -2

#cond_text_dict:
#  positive: The beautiful image of a
#  negative: The disturbing image of a
#  factual: Image of a

cond_text_dict:
  positive: ""
  negative: ""
  factual: ""

#cond_text_list: ["Image of a", "The beautiful image of a", "The disturbing image of a"]
#cond_text_list: [""]


calc_evaluation: True

#ce_scale: 2.925582040227539 #2.43956729 #2.318
clip_scale: 5.6 #2.1430374716828555 #3.746143446 #2.965
text_style_scale: 3.3 #2.9365169098669996 #3.797802783 #3.444
beam_size: 8 #4 #3
num_iterations: 5 #5 # 8
#
std_embedding_vectors_positive: 0 # 0.030191882925088297 #0.028914157
std_embedding_vectors_negative: 0 #0.002273661603177639 #0.020412436

#embedding_vectors_std:
#  positive: 0.05536 #0.028914157
#  negative: 0.007185  #0.020412436

#ZeroCap params
zerocap_clip_scale: 1
zerocap_ce_scale: 0.2
zerocap_beam_size: 5
zerocap_num_iterations: 5
zerocap_text_style_scale: 0

write_debug_tracking_file: False

#arithmetics_style_imgs: [49, 50, 51]
style_img:
  factual: 49
  positive: 50
  negative: 51

labels_dict_idxs:
  positive: 0
  negative: 1

arithmetics_weights: [1, -0.5, 0.5]
img_idx_to_start_from: 0

reset_context_delta: True
calc_fluency: True
imitate_text_style: False
text_to_imitate_list: ["positive"]

epochs: 20
lr: 0.00001
batch_size: 16
margin: 0.26
freeze_after_n_epochs: 4
inner_batch_size: 1
data_name: senticap
best_model_name: checkpoints/best_models/senticap/best_text_style_embedding_model_senticap.pth
model_name: latest_text_style_embedding_model_senticap.pth

mean_vec_emb_file:  checkpoints/best_models/senticap/senticap_mean_class_embedding.p
median_vec_emb_file: checkpoints/best_models/senticap/senticap_median_class_embedding.p
std_vec_emb_file: senticap/senticap_std_class_embedding.p
txt_cls_model_path: checkpoints/best_models/senticap/best_senticap_text_style_classification_model.pth
#txt_cls_model_path: checkpoints/best_models/senticap/pos_neg_best_text_style_classification_model.pth

data_file: #['flickrstyle10k/annotations/funny_train.txt', 'flickrstyle10k/annotations/romantic_train.txt']
experiment_name: cur_time
csv_file_name_train: 'senticap_train.csv'
csv_file_name_test: 'senticap_test.csv'
visual_csv_file_name_train: 'visual_senticap_train.csv'
visual_csv_file_name_test: 'visual_senticap_test.csv'
tgt_file_pairs_list: senticap_pairs_list.p
num_workers: 10
plot_only_clustering: False
#desired_labels: 'all' #[embarrassment, joy, anger, love, annoyance, nervousness]
undesired_label: 'neutral'
resume: False # resume running in wb
load_model: False
run_id:
